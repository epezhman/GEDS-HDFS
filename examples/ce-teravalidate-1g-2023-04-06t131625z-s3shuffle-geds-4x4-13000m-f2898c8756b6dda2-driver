++ id -u
+ myuid=0
++ id -g
+ mygid=0
+ set +e
++ getent passwd 0
+ uidentry=root:x:0:0:root:/root:/bin/bash
+ set -e
+ '[' -z root:x:0:0:root:/root:/bin/bash ']'
+ '[' -z /usr/local/openjdk-11 ']'
+ SPARK_CLASSPATH=':/opt/spark/jars/*'
+ env
+ grep SPARK_JAVA_OPT_
+ sort -t_ -k4 -n
+ sed 's/[^=]*=\(.*\)/\1/g'
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z ']'
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z x ']'
+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*'
+ case "$1" in
+ shift 1
+ CMD=("$SPARK_HOME/bin/spark-submit" --conf "spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS" --deploy-mode client "$@")
+ exec /usr/bin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=10.244.0.252 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class com.github.ehiggs.spark.terasort.TeraValidate local:///opt/spark/jars/spark-terasort-1.2-SNAPSHOT.jar s3a://pezhman-cloudstars/output/terasort/1g--2023-04-06T131625Z-s3shuffle-geds s3a://pezhman-cloudstars/output/terasort-validated/1g--2023-04-06T131625Z-s3shuffle-geds
23/04/06 13:17:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/04/06 13:17:22 INFO SparkContext: Running Spark version 3.3.1
23/04/06 13:17:22 INFO ResourceUtils: ==============================================================
23/04/06 13:17:22 INFO ResourceUtils: No custom resources configured for spark.driver.
23/04/06 13:17:22 INFO ResourceUtils: ==============================================================
23/04/06 13:17:22 INFO SparkContext: Submitted application: TeraValidate
23/04/06 13:17:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 3000, script: , vendor: , cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 13000, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/04/06 13:17:22 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
23/04/06 13:17:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/04/06 13:17:22 INFO SecurityManager: Changing view acls to: root,pezhman.nasirifard
23/04/06 13:17:22 INFO SecurityManager: Changing modify acls to: root,pezhman.nasirifard
23/04/06 13:17:22 INFO SecurityManager: Changing view acls groups to: 
23/04/06 13:17:22 INFO SecurityManager: Changing modify acls groups to: 
23/04/06 13:17:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, pezhman.nasirifard); groups with view permissions: Set(); users  with modify permissions: Set(root, pezhman.nasirifard); groups with modify permissions: Set()
23/04/06 13:17:22 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
23/04/06 13:17:22 INFO SparkEnv: Registering MapOutputTracker
23/04/06 13:17:22 INFO SparkEnv: Registering BlockManagerMaster
23/04/06 13:17:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/04/06 13:17:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/04/06 13:17:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/04/06 13:17:22 INFO DiskBlockManager: Created local directory at /var/data/spark-df504bfc-b724-470b-a6db-f444a61dadbb/blockmgr-f827bff9-eebb-456a-a8a0-41149ea31843
23/04/06 13:17:22 INFO MemoryStore: MemoryStore started with capacity 7.4 GiB
23/04/06 13:17:22 INFO SparkEnv: Registering OutputCommitCoordinator
23/04/06 13:17:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/04/06 13:17:22 INFO SparkContext: Added JAR local:///opt/spark/jars/spark-terasort-1.2-SNAPSHOT.jar at file:/opt/spark/jars/spark-terasort-1.2-SNAPSHOT.jar with timestamp 1680787042127
23/04/06 13:17:22 INFO SparkContext: The JAR local:///opt/spark/jars/spark-terasort-1.2-SNAPSHOT.jar at file:/opt/spark/jars/spark-terasort-1.2-SNAPSHOT.jar has been added already. Overwriting of added jar is not supported in the current version.
23/04/06 13:17:22 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
23/04/06 13:17:23 INFO ExecutorPodsAllocator: Going to request 4 executors from Kubernetes for ResourceProfile Id: 0, target: 4, known: 0, sharedSlotFromPendingPods: 2147483647.
23/04/06 13:17:24 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
23/04/06 13:17:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
23/04/06 13:17:24 INFO NettyBlockTransferService: Server created on spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc:7079
23/04/06 13:17:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/04/06 13:17:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc, 7079, None)
23/04/06 13:17:24 INFO BlockManagerMasterEndpoint: Registering block manager spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc:7079 with 7.4 GiB RAM, BlockManagerId(driver, spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc, 7079, None)
23/04/06 13:17:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc, 7079, None)
23/04/06 13:17:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc, 7079, None)
23/04/06 13:17:24 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
23/04/06 13:17:24 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
23/04/06 13:17:24 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
23/04/06 13:17:27 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.1.173:47752) with ID 2,  ResourceProfileId 0
23/04/06 13:17:27 INFO BlockManagerMasterEndpoint: Registering block manager 10.244.1.173:35777 with 7.4 GiB RAM, BlockManagerId(2, 10.244.1.173, 35777, None)
23/04/06 13:17:28 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.4.28:56074) with ID 1,  ResourceProfileId 0
23/04/06 13:17:28 INFO BlockManagerMasterEndpoint: Registering block manager 10.244.4.28:37421 with 7.4 GiB RAM, BlockManagerId(1, 10.244.4.28, 37421, None)
23/04/06 13:17:28 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.10.147:36816) with ID 4,  ResourceProfileId 0
23/04/06 13:17:28 INFO BlockManagerMasterEndpoint: Registering block manager 10.244.10.147:43309 with 7.4 GiB RAM, BlockManagerId(4, 10.244.10.147, 43309, None)
23/04/06 13:17:38 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.11.195:38518) with ID 3,  ResourceProfileId 0
23/04/06 13:17:38 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
23/04/06 13:17:38 INFO BlockManagerMasterEndpoint: Registering block manager 10.244.11.195:46275 with 7.4 GiB RAM, BlockManagerId(3, 10.244.11.195, 46275, None)
23/04/06 13:17:38 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
23/04/06 13:17:38 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
23/04/06 13:17:38 INFO MetricsSystemImpl: s3a-file-system metrics system started
23/04/06 13:17:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 293.5 KiB, free 7.4 GiB)
23/04/06 13:17:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 7.4 GiB)
23/04/06 13:17:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc:7079 (size: 32.7 KiB, free: 7.4 GiB)
23/04/06 13:17:39 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at TeraValidate.scala:60
23/04/06 13:17:40 INFO FileInputFormat: Total input files to process : 0
23/04/06 13:17:40 INFO SparkContext: Starting job: collect at TeraValidate.scala:98
23/04/06 13:17:40 INFO DAGScheduler: Job 0 finished: collect at TeraValidate.scala:98, took 0.004485 s
23/04/06 13:17:40 INFO SparkContext: Starting job: count at TeraValidate.scala:101
23/04/06 13:17:40 INFO DAGScheduler: Job 1 finished: count at TeraValidate.scala:101, took 0.000196 s
num records: 0
checksum: 0
num records: 0
checksum: 0
partitions are properly sorted
23/04/06 13:17:40 INFO SparkUI: Stopped Spark web UI at http://spark-7792b18756b6e22d-driver-svc.pezhman-cloudstars.svc:4040
23/04/06 13:17:40 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
23/04/06 13:17:40 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
23/04/06 13:17:40 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
23/04/06 13:17:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/04/06 13:17:40 INFO MemoryStore: MemoryStore cleared
23/04/06 13:17:40 INFO BlockManager: BlockManager stopped
23/04/06 13:17:40 INFO BlockManagerMaster: BlockManagerMaster stopped
23/04/06 13:17:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/04/06 13:17:40 INFO SparkContext: Successfully stopped SparkContext
23/04/06 13:17:40 INFO ShutdownHookManager: Shutdown hook called
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-44d58424-3c19-40af-a1c0-b9ee84fb0caa
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /var/data/spark-df504bfc-b724-470b-a6db-f444a61dadbb/spark-a7d42086-3b03-4c47-a5e9-917c02234537
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-1ce20668-0156-4a52-8c6b-f8324d19cfc4
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-33e28297-ea5b-412e-8975-a47d33696b08
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d321b8e-4f50-4aeb-92d9-bed09186ba14
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-d4517eba-5892-4ff0-a3c5-281a52574077
23/04/06 13:17:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-05ead9d8-647b-461c-9a16-41171f651d06
23/04/06 13:17:40 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
23/04/06 13:17:40 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
23/04/06 13:17:40 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
